{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 21:46:29.926584: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-14 21:46:29.928935: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-14 21:46:29.962342: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-14 21:46:29.962395: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-14 21:46:29.962437: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-14 21:46:29.969257: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-14 21:46:29.970698: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-14 21:46:30.984696: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from matplotlib import cm, colors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import dataUtils as du\n",
    "import myModels as mm\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMEPOCHS = 100\n",
    "BATCHSIZE = 128\n",
    "PHASEMAX = 100\n",
    "PERCENTPILEUP = 0.5\n",
    "AUGMENTATION = 8\n",
    "TRACELENGTH = 250\n",
    "INPUTSIZE = TRACELENGTH-4*AUGMENTATION\n",
    "VALIDATIONSPLIT = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  269082\n",
      "Test size:  269083\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "x_train, x_test, y_train, y_test = du.GetDataSet(type=\"phase\",\n",
    "                                                 fname=\"DataSmallFloat.root\",\n",
    "                                                 tname=\"OutputTree\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase\n",
    "- Arch prune starting from bigger model (current mse: 1.7)\n",
    "- Weight prune starting from smaller model (current mse: 1.7) \n",
    "\n",
    "* goal is mse of 1.0 (2ns)\n",
    "\n",
    "# Amp\n",
    "- Arch prune starting from bigger model (current mse: 0.11)\n",
    "\n",
    "* goal 0.05 \n",
    "\n",
    "# Pileup\n",
    "- No early stopping (current acc 0.97)\n",
    "\n",
    "* goal 0.99 \n",
    "\n",
    "- Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)\n",
    "\n",
    "\n",
    "def evaluate_model(interpreter, x_test, y_test):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on ever y image in the \"test\" dataset.\n",
    "    prediction = []\n",
    "    for i, test_trace in enumerate(x_test):\n",
    "        if i % 1000 == 0:\n",
    "            print('Evaluated on {n} results so far.'.format(n=i))\n",
    "        \n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "        # the model's input data format.\n",
    "        test_trace = np.expand_dims(test_trace, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_trace)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        y_pred = np.argmax(output()[0])\n",
    "        prediction.append(y_pred)\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    prediction = np.array(prediction)\n",
    "    mse = np.mean((prediction - y_test)**2)\n",
    "    return mse\n",
    "\n",
    "\n",
    "\n",
    "def plot_separation_lines(height, width):\n",
    "\n",
    "    block_size = [1, 4]\n",
    "\n",
    "    # Add separation lines to the figure.\n",
    "    num_hlines = int((height - 1) / block_size[0])\n",
    "    num_vlines = int((width - 1) / block_size[1])\n",
    "    line_y_pos = [y * block_size[0] for y in range(1, num_hlines + 1)]\n",
    "    line_x_pos = [x * block_size[1] for x in range(1, num_vlines + 1)]\n",
    "\n",
    "    for y_pos in line_y_pos:\n",
    "        plt.plot([-0.5, width], [y_pos - 0.5 , y_pos - 0.5], color='w')\n",
    "\n",
    "    for x_pos in line_x_pos:\n",
    "        plt.plot([x_pos - 0.5, x_pos - 0.5], [-0.5, height], color='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PhaseNet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (Conv1D)              (None, 209, 64)           704       \n",
      "                                                                 \n",
      " dropout1 (Dropout)          (None, 209, 64)           0         \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 209, 64)           4160      \n",
      "                                                                 \n",
      " dropout2 (Dropout)          (None, 209, 64)           0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 209, 64)           8256      \n",
      "                                                                 \n",
      " dropout3 (Dropout)          (None, 209, 64)           0         \n",
      "                                                                 \n",
      " flat1 (Flatten)             (None, 13376)             0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 128)               1712256   \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1725505 (6.58 MB)\n",
      "Trainable params: 1725505 (6.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1262/1262 [==============================] - 119s 93ms/step - loss: 71.0111 - mean_squared_error: 71.0111 - val_loss: 31.0601 - val_mean_squared_error: 31.0601\n",
      "Epoch 2/100\n",
      "1262/1262 [==============================] - 111s 88ms/step - loss: 21.2815 - mean_squared_error: 21.2815 - val_loss: 15.0538 - val_mean_squared_error: 15.0538\n",
      "Epoch 3/100\n",
      "1262/1262 [==============================] - 107s 85ms/step - loss: 15.8677 - mean_squared_error: 15.8677 - val_loss: 10.6243 - val_mean_squared_error: 10.6243\n",
      "Epoch 4/100\n",
      "1262/1262 [==============================] - 117s 93ms/step - loss: 11.2475 - mean_squared_error: 11.2475 - val_loss: 8.3401 - val_mean_squared_error: 8.3401\n",
      "Epoch 5/100\n",
      "1262/1262 [==============================] - 108s 86ms/step - loss: 8.8308 - mean_squared_error: 8.8308 - val_loss: 6.1253 - val_mean_squared_error: 6.1253\n",
      "Epoch 6/100\n",
      "1262/1262 [==============================] - 110s 87ms/step - loss: 7.4000 - mean_squared_error: 7.4000 - val_loss: 5.1798 - val_mean_squared_error: 5.1798\n",
      "Epoch 7/100\n",
      "1262/1262 [==============================] - 108s 86ms/step - loss: 6.4833 - mean_squared_error: 6.4833 - val_loss: 4.1925 - val_mean_squared_error: 4.1925\n",
      "Epoch 8/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 5.6869 - mean_squared_error: 5.6869 - val_loss: 4.0891 - val_mean_squared_error: 4.0891\n",
      "Epoch 9/100\n",
      "1262/1262 [==============================] - 108s 86ms/step - loss: 5.1781 - mean_squared_error: 5.1781 - val_loss: 3.5819 - val_mean_squared_error: 3.5819\n",
      "Epoch 10/100\n",
      "1262/1262 [==============================] - 117s 93ms/step - loss: 4.7342 - mean_squared_error: 4.7342 - val_loss: 5.6172 - val_mean_squared_error: 5.6172\n",
      "Epoch 11/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 4.4698 - mean_squared_error: 4.4698 - val_loss: 3.4545 - val_mean_squared_error: 3.4545\n",
      "Epoch 12/100\n",
      "1262/1262 [==============================] - 117s 93ms/step - loss: 4.1430 - mean_squared_error: 4.1430 - val_loss: 3.8175 - val_mean_squared_error: 3.8175\n",
      "Epoch 13/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 4.0908 - mean_squared_error: 4.0908 - val_loss: 3.8325 - val_mean_squared_error: 3.8325\n",
      "Epoch 14/100\n",
      "1262/1262 [==============================] - 108s 86ms/step - loss: 3.8685 - mean_squared_error: 3.8685 - val_loss: 2.8282 - val_mean_squared_error: 2.8282\n",
      "Epoch 15/100\n",
      "1262/1262 [==============================] - 109s 87ms/step - loss: 3.7205 - mean_squared_error: 3.7205 - val_loss: 2.9937 - val_mean_squared_error: 2.9937\n",
      "Epoch 16/100\n",
      "1262/1262 [==============================] - 107s 85ms/step - loss: 3.6199 - mean_squared_error: 3.6199 - val_loss: 2.9893 - val_mean_squared_error: 2.9893\n",
      "Epoch 17/100\n",
      "1262/1262 [==============================] - 105s 83ms/step - loss: 3.5559 - mean_squared_error: 3.5559 - val_loss: 2.7898 - val_mean_squared_error: 2.7898\n",
      "Epoch 18/100\n",
      "1262/1262 [==============================] - 106s 84ms/step - loss: 3.3630 - mean_squared_error: 3.3630 - val_loss: 2.5498 - val_mean_squared_error: 2.5498\n",
      "Epoch 19/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 3.3057 - mean_squared_error: 3.3057 - val_loss: 2.8424 - val_mean_squared_error: 2.8424\n",
      "Epoch 20/100\n",
      "1262/1262 [==============================] - 108s 86ms/step - loss: 3.1973 - mean_squared_error: 3.1973 - val_loss: 2.4969 - val_mean_squared_error: 2.4969\n",
      "Epoch 21/100\n",
      "1262/1262 [==============================] - 117s 93ms/step - loss: 3.1583 - mean_squared_error: 3.1583 - val_loss: 2.8741 - val_mean_squared_error: 2.8741\n",
      "Epoch 22/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 3.0523 - mean_squared_error: 3.0523 - val_loss: 2.5157 - val_mean_squared_error: 2.5157\n",
      "Epoch 23/100\n",
      "1262/1262 [==============================] - 116s 92ms/step - loss: 3.0084 - mean_squared_error: 3.0084 - val_loss: 2.4593 - val_mean_squared_error: 2.4593\n",
      "Epoch 24/100\n",
      "1262/1262 [==============================] - 117s 92ms/step - loss: 2.9283 - mean_squared_error: 2.9283 - val_loss: 2.4806 - val_mean_squared_error: 2.4806\n",
      "Epoch 25/100\n",
      "1262/1262 [==============================] - 109s 87ms/step - loss: 2.9083 - mean_squared_error: 2.9083 - val_loss: 2.7620 - val_mean_squared_error: 2.7620\n",
      "Epoch 26/100\n",
      "1262/1262 [==============================] - 110s 87ms/step - loss: 2.8885 - mean_squared_error: 2.8885 - val_loss: 2.3794 - val_mean_squared_error: 2.3794\n",
      "Epoch 27/100\n",
      "1262/1262 [==============================] - 112s 88ms/step - loss: 2.7696 - mean_squared_error: 2.7696 - val_loss: 2.4068 - val_mean_squared_error: 2.4068\n",
      "Epoch 28/100\n",
      "1262/1262 [==============================] - 110s 87ms/step - loss: 2.7097 - mean_squared_error: 2.7097 - val_loss: 2.2338 - val_mean_squared_error: 2.2338\n",
      "Epoch 29/100\n",
      "1262/1262 [==============================] - 110s 87ms/step - loss: 2.6999 - mean_squared_error: 2.6999 - val_loss: 3.3377 - val_mean_squared_error: 3.3377\n",
      "Epoch 30/100\n",
      "1262/1262 [==============================] - 110s 87ms/step - loss: 2.6466 - mean_squared_error: 2.6466 - val_loss: 2.4461 - val_mean_squared_error: 2.4461\n",
      "Epoch 31/100\n",
      "1262/1262 [==============================] - 110s 88ms/step - loss: 2.6258 - mean_squared_error: 2.6258 - val_loss: 2.3674 - val_mean_squared_error: 2.3674\n",
      "Epoch 32/100\n",
      "1262/1262 [==============================] - 110s 88ms/step - loss: 2.5677 - mean_squared_error: 2.5677 - val_loss: 3.3414 - val_mean_squared_error: 3.3414\n",
      "Epoch 33/100\n",
      "1262/1262 [==============================] - 112s 89ms/step - loss: 2.5821 - mean_squared_error: 2.5821 - val_loss: 2.2168 - val_mean_squared_error: 2.2168\n",
      "Epoch 34/100\n",
      "1262/1262 [==============================] - 111s 88ms/step - loss: 2.5516 - mean_squared_error: 2.5516 - val_loss: 3.0413 - val_mean_squared_error: 3.0413\n",
      "Epoch 35/100\n",
      "1262/1262 [==============================] - 119s 94ms/step - loss: 2.5118 - mean_squared_error: 2.5118 - val_loss: 2.1626 - val_mean_squared_error: 2.1626\n",
      "Epoch 36/100\n",
      "1262/1262 [==============================] - 120s 95ms/step - loss: 2.5018 - mean_squared_error: 2.5018 - val_loss: 2.7285 - val_mean_squared_error: 2.7285\n",
      "Epoch 37/100\n",
      "1262/1262 [==============================] - 111s 88ms/step - loss: 2.4644 - mean_squared_error: 2.4644 - val_loss: 2.1244 - val_mean_squared_error: 2.1244\n",
      "Epoch 38/100\n",
      "1262/1262 [==============================] - 110s 88ms/step - loss: 2.4340 - mean_squared_error: 2.4340 - val_loss: 2.2033 - val_mean_squared_error: 2.2033\n",
      "Epoch 39/100\n",
      "1262/1262 [==============================] - 112s 89ms/step - loss: 2.3805 - mean_squared_error: 2.3805 - val_loss: 2.1497 - val_mean_squared_error: 2.1497\n",
      "Epoch 40/100\n",
      "1262/1262 [==============================] - 112s 89ms/step - loss: 2.3995 - mean_squared_error: 2.3995 - val_loss: 2.2694 - val_mean_squared_error: 2.2694\n",
      "Epoch 41/100\n",
      "1262/1262 [==============================] - 113s 89ms/step - loss: 2.3803 - mean_squared_error: 2.3803 - val_loss: 2.5326 - val_mean_squared_error: 2.5326\n",
      "Epoch 42/100\n",
      "1262/1262 [==============================] - 111s 88ms/step - loss: 2.3735 - mean_squared_error: 2.3735 - val_loss: 2.2656 - val_mean_squared_error: 2.2656\n",
      "Epoch 43/100\n",
      "1262/1262 [==============================] - 111s 88ms/step - loss: 2.3068 - mean_squared_error: 2.3068 - val_loss: 2.9989 - val_mean_squared_error: 2.9989\n",
      "Epoch 44/100\n",
      "1262/1262 [==============================] - 114s 90ms/step - loss: 2.3739 - mean_squared_error: 2.3739 - val_loss: 2.6124 - val_mean_squared_error: 2.6124\n",
      "Epoch 45/100\n",
      "1262/1262 [==============================] - 114s 90ms/step - loss: 2.3213 - mean_squared_error: 2.3213 - val_loss: 2.3632 - val_mean_squared_error: 2.3632\n",
      "Epoch 46/100\n",
      "1262/1262 [==============================] - 111s 88ms/step - loss: 2.2933 - mean_squared_error: 2.2933 - val_loss: 2.1033 - val_mean_squared_error: 2.1033\n",
      "Epoch 47/100\n",
      "1262/1262 [==============================] - 112s 89ms/step - loss: 2.2832 - mean_squared_error: 2.2832 - val_loss: 2.1278 - val_mean_squared_error: 2.1278\n",
      "Epoch 48/100\n",
      "1262/1262 [==============================] - 113s 89ms/step - loss: 2.2824 - mean_squared_error: 2.2824 - val_loss: 2.0264 - val_mean_squared_error: 2.0264\n",
      "Epoch 49/100\n",
      "1262/1262 [==============================] - 113s 90ms/step - loss: 2.2364 - mean_squared_error: 2.2364 - val_loss: 2.2597 - val_mean_squared_error: 2.2597\n",
      "Epoch 50/100\n",
      "1262/1262 [==============================] - 112s 89ms/step - loss: 2.2431 - mean_squared_error: 2.2431 - val_loss: 2.2178 - val_mean_squared_error: 2.2178\n",
      "Epoch 51/100\n",
      "1262/1262 [==============================] - 112s 89ms/step - loss: 2.2468 - mean_squared_error: 2.2468 - val_loss: 2.2743 - val_mean_squared_error: 2.2743\n",
      "Epoch 52/100\n",
      "1262/1262 [==============================] - 113s 89ms/step - loss: 2.2040 - mean_squared_error: 2.2040 - val_loss: 2.8432 - val_mean_squared_error: 2.8432\n",
      "Epoch 53/100\n",
      "1262/1262 [==============================] - 117s 92ms/step - loss: 2.2002 - mean_squared_error: 2.2002 - val_loss: 2.7185 - val_mean_squared_error: 2.7185\n",
      "Epoch 54/100\n",
      "1262/1262 [==============================] - 122s 96ms/step - loss: 2.1790 - mean_squared_error: 2.1790 - val_loss: 2.2046 - val_mean_squared_error: 2.2046\n",
      "Epoch 55/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 2.1568 - mean_squared_error: 2.1568 - val_loss: 2.0593 - val_mean_squared_error: 2.0593\n",
      "Epoch 56/100\n",
      "1262/1262 [==============================] - 110s 87ms/step - loss: 2.1531 - mean_squared_error: 2.1531 - val_loss: 2.0921 - val_mean_squared_error: 2.0921\n",
      "Epoch 57/100\n",
      "1262/1262 [==============================] - 110s 88ms/step - loss: 2.1773 - mean_squared_error: 2.1773 - val_loss: 2.3988 - val_mean_squared_error: 2.3988\n",
      "Epoch 58/100\n",
      "1262/1262 [==============================] - 111s 88ms/step - loss: 2.1468 - mean_squared_error: 2.1468 - val_loss: 2.1522 - val_mean_squared_error: 2.1522\n",
      "Test Mean Squared Error: 1.863574504852295\n",
      "Saved model to: /tmp/tmptk2yg6my.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmengel/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PhaseNet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_conv1   (None, 209, 64)           1346      \n",
      " (PruneLowMagnitude)                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_dropou  (None, 209, 64)           1         \n",
      " t1 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2   (None, 209, 64)           8258      \n",
      " (PruneLowMagnitude)                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_dropou  (None, 209, 64)           1         \n",
      " t2 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_conv3   (None, 209, 64)           16450     \n",
      " (PruneLowMagnitude)                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_dropou  (None, 209, 64)           1         \n",
      " t3 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_flat1   (None, 13376)             1         \n",
      " (PruneLowMagnitude)                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_dense1  (None, 128)               3424386   \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_output  (None, 1)                 259       \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3450703 (13.16 MB)\n",
      "Trainable params: 1725505 (6.58 MB)\n",
      "Non-trainable params: 1725198 (6.58 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1262/1262 [==============================] - 111s 86ms/step - loss: 3.0256 - mse: 3.0256 - val_loss: 2.0893 - val_mse: 2.0893\n",
      "Epoch 2/100\n",
      "1262/1262 [==============================] - 107s 85ms/step - loss: 2.1280 - mse: 2.1280 - val_loss: 2.2437 - val_mse: 2.2437\n",
      "Epoch 3/100\n",
      "1262/1262 [==============================] - 108s 86ms/step - loss: 2.1322 - mse: 2.1322 - val_loss: 2.0507 - val_mse: 2.0507\n",
      "Epoch 4/100\n",
      "1262/1262 [==============================] - 118s 93ms/step - loss: 2.0883 - mse: 2.0883 - val_loss: 2.1545 - val_mse: 2.1545\n",
      "Epoch 5/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 2.0864 - mse: 2.0864 - val_loss: 2.1791 - val_mse: 2.1791\n",
      "Epoch 6/100\n",
      "1262/1262 [==============================] - 116s 92ms/step - loss: 2.0605 - mse: 2.0605 - val_loss: 2.0401 - val_mse: 2.0401\n",
      "Epoch 7/100\n",
      "1262/1262 [==============================] - 107s 85ms/step - loss: 2.0467 - mse: 2.0467 - val_loss: 2.3079 - val_mse: 2.3079\n",
      "Epoch 8/100\n",
      "1262/1262 [==============================] - 107s 85ms/step - loss: 2.0230 - mse: 2.0230 - val_loss: 2.0630 - val_mse: 2.0630\n",
      "Epoch 9/100\n",
      "1262/1262 [==============================] - 109s 87ms/step - loss: 1.9921 - mse: 1.9921 - val_loss: 2.1572 - val_mse: 2.1572\n",
      "Epoch 10/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 1.9809 - mse: 1.9809 - val_loss: 2.0563 - val_mse: 2.0563\n",
      "Epoch 11/100\n",
      "1262/1262 [==============================] - 116s 92ms/step - loss: 2.0090 - mse: 2.0090 - val_loss: 2.1580 - val_mse: 2.1580\n",
      "Epoch 12/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 1.9742 - mse: 1.9742 - val_loss: 2.2239 - val_mse: 2.2239\n",
      "Epoch 13/100\n",
      "1262/1262 [==============================] - 115s 91ms/step - loss: 1.9270 - mse: 1.9270 - val_loss: 2.0605 - val_mse: 2.0605\n",
      "Epoch 14/100\n",
      "1262/1262 [==============================] - 107s 85ms/step - loss: 1.9991 - mse: 1.9991 - val_loss: 2.1546 - val_mse: 2.1546\n",
      "Epoch 15/100\n",
      "1262/1262 [==============================] - 113s 90ms/step - loss: 1.9620 - mse: 1.9620 - val_loss: 2.2200 - val_mse: 2.2200\n",
      "Epoch 16/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 1.9564 - mse: 1.9564 - val_loss: 2.0391 - val_mse: 2.0391\n",
      "Epoch 17/100\n",
      "1262/1262 [==============================] - 109s 87ms/step - loss: 1.9475 - mse: 1.9475 - val_loss: 2.1960 - val_mse: 2.1960\n",
      "Epoch 18/100\n",
      "1262/1262 [==============================] - 110s 87ms/step - loss: 1.9032 - mse: 1.9032 - val_loss: 2.0055 - val_mse: 2.0055\n",
      "Epoch 19/100\n",
      "1262/1262 [==============================] - 107s 85ms/step - loss: 1.9491 - mse: 1.9491 - val_loss: 2.1602 - val_mse: 2.1602\n",
      "Epoch 20/100\n",
      "1262/1262 [==============================] - 115s 91ms/step - loss: 1.8728 - mse: 1.8728 - val_loss: 2.0472 - val_mse: 2.0472\n",
      "Epoch 21/100\n",
      "1262/1262 [==============================] - 110s 87ms/step - loss: 1.8875 - mse: 1.8875 - val_loss: 2.1381 - val_mse: 2.1381\n",
      "Epoch 22/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 1.9423 - mse: 1.9423 - val_loss: 2.0729 - val_mse: 2.0729\n",
      "Epoch 23/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 1.9298 - mse: 1.9298 - val_loss: 2.0036 - val_mse: 2.0036\n",
      "Epoch 24/100\n",
      "1262/1262 [==============================] - 110s 87ms/step - loss: 1.9031 - mse: 1.9031 - val_loss: 2.0370 - val_mse: 2.0370\n",
      "Epoch 25/100\n",
      "1262/1262 [==============================] - 108s 85ms/step - loss: 1.8902 - mse: 1.8902 - val_loss: 2.0759 - val_mse: 2.0759\n",
      "Epoch 26/100\n",
      "1262/1262 [==============================] - 115s 91ms/step - loss: 1.8673 - mse: 1.8673 - val_loss: 2.0069 - val_mse: 2.0069\n",
      "Epoch 27/100\n",
      "1262/1262 [==============================] - 109s 87ms/step - loss: 1.8857 - mse: 1.8857 - val_loss: 2.0756 - val_mse: 2.0756\n",
      "Epoch 28/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 1.8723 - mse: 1.8723 - val_loss: 1.9985 - val_mse: 1.9985\n",
      "Epoch 29/100\n",
      "1262/1262 [==============================] - 109s 87ms/step - loss: 1.8724 - mse: 1.8724 - val_loss: 2.1028 - val_mse: 2.1028\n",
      "Epoch 30/100\n",
      "1262/1262 [==============================] - 116s 92ms/step - loss: 1.8449 - mse: 1.8449 - val_loss: 2.0373 - val_mse: 2.0373\n",
      "Epoch 31/100\n",
      "1262/1262 [==============================] - 107s 85ms/step - loss: 1.8714 - mse: 1.8714 - val_loss: 1.9941 - val_mse: 1.9941\n",
      "Epoch 32/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 1.8363 - mse: 1.8363 - val_loss: 2.0826 - val_mse: 2.0826\n",
      "Epoch 33/100\n",
      "1262/1262 [==============================] - 110s 87ms/step - loss: 1.8457 - mse: 1.8457 - val_loss: 2.1188 - val_mse: 2.1188\n",
      "Epoch 34/100\n",
      "1262/1262 [==============================] - 110s 87ms/step - loss: 1.8315 - mse: 1.8315 - val_loss: 2.0931 - val_mse: 2.0931\n",
      "Epoch 35/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 1.9020 - mse: 1.9020 - val_loss: 1.9522 - val_mse: 1.9522\n",
      "Epoch 36/100\n",
      "1262/1262 [==============================] - 116s 92ms/step - loss: 1.8579 - mse: 1.8579 - val_loss: 2.0169 - val_mse: 2.0169\n",
      "Epoch 37/100\n",
      "1262/1262 [==============================] - 108s 86ms/step - loss: 1.9250 - mse: 1.9250 - val_loss: 2.1177 - val_mse: 2.1177\n",
      "Epoch 38/100\n",
      "1262/1262 [==============================] - 117s 92ms/step - loss: 1.8564 - mse: 1.8564 - val_loss: 1.9775 - val_mse: 1.9775\n",
      "Epoch 39/100\n",
      "1262/1262 [==============================] - 110s 87ms/step - loss: 1.8689 - mse: 1.8689 - val_loss: 2.0010 - val_mse: 2.0010\n",
      "Epoch 40/100\n",
      "1262/1262 [==============================] - 108s 85ms/step - loss: 1.8582 - mse: 1.8582 - val_loss: 2.0119 - val_mse: 2.0119\n",
      "Epoch 41/100\n",
      "1262/1262 [==============================] - 108s 85ms/step - loss: 1.8525 - mse: 1.8525 - val_loss: 2.0341 - val_mse: 2.0341\n",
      "Epoch 42/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 1.8457 - mse: 1.8457 - val_loss: 2.0782 - val_mse: 2.0782\n",
      "Epoch 43/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 1.8103 - mse: 1.8103 - val_loss: 2.0242 - val_mse: 2.0242\n",
      "Epoch 44/100\n",
      "1262/1262 [==============================] - 116s 92ms/step - loss: 1.8315 - mse: 1.8315 - val_loss: 2.2553 - val_mse: 2.2553\n",
      "Epoch 45/100\n",
      "1262/1262 [==============================] - 108s 85ms/step - loss: 1.8257 - mse: 1.8257 - val_loss: 2.0631 - val_mse: 2.0631\n",
      "Epoch 46/100\n",
      "1262/1262 [==============================] - 109s 86ms/step - loss: 1.8250 - mse: 1.8250 - val_loss: 2.0011 - val_mse: 2.0011\n",
      "Epoch 47/100\n",
      "1262/1262 [==============================] - 118s 93ms/step - loss: 1.8983 - mse: 1.8983 - val_loss: 2.0471 - val_mse: 2.0471\n",
      "Epoch 48/100\n",
      "1262/1262 [==============================] - 110s 88ms/step - loss: 1.8806 - mse: 1.8806 - val_loss: 2.1108 - val_mse: 2.1108\n",
      "Epoch 49/100\n",
      "1262/1262 [==============================] - 112s 89ms/step - loss: 1.8442 - mse: 1.8442 - val_loss: 2.0309 - val_mse: 2.0309\n",
      "Epoch 50/100\n",
      "1262/1262 [==============================] - 114s 91ms/step - loss: 1.8463 - mse: 1.8463 - val_loss: 2.3681 - val_mse: 2.3681\n",
      "Epoch 51/100\n",
      "1262/1262 [==============================] - 113s 89ms/step - loss: 1.8389 - mse: 1.8389 - val_loss: 1.9927 - val_mse: 1.9927\n",
      "Epoch 52/100\n",
      "1262/1262 [==============================] - 119s 95ms/step - loss: 1.8396 - mse: 1.8396 - val_loss: 2.0437 - val_mse: 2.0437\n",
      "Epoch 53/100\n",
      "1262/1262 [==============================] - 112s 89ms/step - loss: 1.8103 - mse: 1.8103 - val_loss: 1.9635 - val_mse: 1.9635\n",
      "Epoch 54/100\n",
      "1262/1262 [==============================] - 113s 90ms/step - loss: 1.8119 - mse: 1.8119 - val_loss: 2.0307 - val_mse: 2.0307\n",
      "Epoch 55/100\n",
      "1262/1262 [==============================] - 113s 90ms/step - loss: 1.8082 - mse: 1.8082 - val_loss: 2.0262 - val_mse: 2.0262\n",
      "Epoch 56/100\n",
      "1262/1262 [==============================] - 113s 90ms/step - loss: 1.8173 - mse: 1.8173 - val_loss: 1.9937 - val_mse: 1.9937\n",
      "Epoch 57/100\n",
      "1262/1262 [==============================] - 112s 89ms/step - loss: 1.8123 - mse: 1.8123 - val_loss: 1.9988 - val_mse: 1.9988\n",
      "Epoch 58/100\n",
      "1262/1262 [==============================] - 113s 90ms/step - loss: 1.8751 - mse: 1.8751 - val_loss: 2.0466 - val_mse: 2.0466\n",
      "Epoch 59/100\n",
      "1262/1262 [==============================] - 115s 91ms/step - loss: 1.8600 - mse: 1.8600 - val_loss: 2.0784 - val_mse: 2.0784\n",
      "Epoch 60/100\n",
      "1262/1262 [==============================] - 114s 90ms/step - loss: 1.8285 - mse: 1.8285 - val_loss: 2.1962 - val_mse: 2.1962\n",
      "Epoch 61/100\n",
      "1262/1262 [==============================] - 113s 90ms/step - loss: 1.8322 - mse: 1.8322 - val_loss: 2.1316 - val_mse: 2.1316\n",
      "Epoch 62/100\n",
      "1262/1262 [==============================] - 113s 90ms/step - loss: 1.8159 - mse: 1.8159 - val_loss: 1.9612 - val_mse: 1.9612\n",
      "Epoch 63/100\n",
      "1262/1262 [==============================] - 121s 96ms/step - loss: 1.8401 - mse: 1.8401 - val_loss: 2.0564 - val_mse: 2.0564\n",
      "Epoch 64/100\n",
      "1262/1262 [==============================] - 115s 91ms/step - loss: 1.8013 - mse: 1.8013 - val_loss: 2.0523 - val_mse: 2.0523\n",
      "Epoch 65/100\n",
      "1262/1262 [==============================] - 115s 91ms/step - loss: 1.8131 - mse: 1.8131 - val_loss: 2.0618 - val_mse: 2.0618\n",
      "Epoch 66/100\n",
      "1262/1262 [==============================] - 115s 91ms/step - loss: 1.8028 - mse: 1.8028 - val_loss: 2.0146 - val_mse: 2.0146\n",
      "Epoch 67/100\n",
      "1262/1262 [==============================] - 113s 90ms/step - loss: 1.7906 - mse: 1.7906 - val_loss: 1.9987 - val_mse: 1.9987\n",
      "Epoch 68/100\n",
      "1262/1262 [==============================] - 113s 89ms/step - loss: 1.7923 - mse: 1.7923 - val_loss: 2.0142 - val_mse: 2.0142\n",
      "Epoch 69/100\n",
      "1262/1262 [==============================] - 113s 90ms/step - loss: 1.7905 - mse: 1.7905 - val_loss: 2.0059 - val_mse: 2.0059\n",
      "Epoch 70/100\n",
      "1262/1262 [==============================] - 122s 97ms/step - loss: 1.8024 - mse: 1.8024 - val_loss: 2.2061 - val_mse: 2.2061\n",
      "Epoch 71/100\n",
      "1262/1262 [==============================] - 115s 91ms/step - loss: 1.7569 - mse: 1.7569 - val_loss: 1.9843 - val_mse: 1.9843\n",
      "Epoch 72/100\n",
      "1262/1262 [==============================] - 114s 90ms/step - loss: 1.8333 - mse: 1.8333 - val_loss: 2.1132 - val_mse: 2.1132\n",
      "Epoch 73/100\n",
      "1262/1262 [==============================] - 115s 91ms/step - loss: 1.8297 - mse: 1.8297 - val_loss: 2.1461 - val_mse: 2.1461\n",
      "Epoch 74/100\n",
      "1262/1262 [==============================] - 113s 89ms/step - loss: 1.8309 - mse: 1.8309 - val_loss: 2.0088 - val_mse: 2.0088\n",
      "Epoch 75/100\n",
      "1262/1262 [==============================] - 113s 90ms/step - loss: 1.8026 - mse: 1.8026 - val_loss: 2.1149 - val_mse: 2.1149\n",
      "Epoch 76/100\n",
      "1262/1262 [==============================] - 114s 91ms/step - loss: 1.7802 - mse: 1.7802 - val_loss: 2.1254 - val_mse: 2.1254\n",
      "Epoch 77/100\n",
      "1262/1262 [==============================] - 114s 90ms/step - loss: 1.7989 - mse: 1.7989 - val_loss: 2.1106 - val_mse: 2.1106\n",
      "Epoch 78/100\n",
      "1262/1262 [==============================] - 115s 91ms/step - loss: 1.8005 - mse: 1.8005 - val_loss: 1.9427 - val_mse: 1.9427\n",
      "Epoch 79/100\n",
      "1262/1262 [==============================] - 116s 92ms/step - loss: 1.7574 - mse: 1.7574 - val_loss: 1.9993 - val_mse: 1.9993\n",
      "Epoch 80/100\n",
      "1262/1262 [==============================] - 114s 90ms/step - loss: 1.7946 - mse: 1.7946 - val_loss: 1.9290 - val_mse: 1.9290\n",
      "Epoch 81/100\n",
      "1262/1262 [==============================] - 114s 90ms/step - loss: 1.7775 - mse: 1.7775 - val_loss: 2.0433 - val_mse: 2.0433\n",
      "Epoch 82/100\n",
      "1262/1262 [==============================] - 112s 89ms/step - loss: 1.7921 - mse: 1.7921 - val_loss: 2.0340 - val_mse: 2.0340\n",
      "Epoch 83/100\n",
      "1262/1262 [==============================] - 118s 94ms/step - loss: 1.7644 - mse: 1.7644 - val_loss: 2.0040 - val_mse: 2.0040\n",
      "Epoch 84/100\n",
      "1262/1262 [==============================] - 118s 94ms/step - loss: 1.7732 - mse: 1.7732 - val_loss: 1.9508 - val_mse: 1.9508\n",
      "Epoch 85/100\n",
      "1262/1262 [==============================] - 112s 88ms/step - loss: 1.7781 - mse: 1.7781 - val_loss: 2.0049 - val_mse: 2.0049\n",
      "Epoch 86/100\n",
      "1262/1262 [==============================] - 118s 94ms/step - loss: 1.7540 - mse: 1.7540 - val_loss: 2.0633 - val_mse: 2.0633\n",
      "Epoch 87/100\n",
      "1262/1262 [==============================] - 110s 87ms/step - loss: 1.7405 - mse: 1.7405 - val_loss: 1.9698 - val_mse: 1.9698\n",
      "Epoch 88/100\n",
      "1262/1262 [==============================] - 118s 93ms/step - loss: 1.7523 - mse: 1.7523 - val_loss: 1.9810 - val_mse: 1.9810\n",
      "Epoch 89/100\n",
      "1262/1262 [==============================] - 111s 88ms/step - loss: 1.7479 - mse: 1.7479 - val_loss: 2.0987 - val_mse: 2.0987\n",
      "Epoch 90/100\n",
      "1262/1262 [==============================] - 112s 88ms/step - loss: 1.7646 - mse: 1.7646 - val_loss: 2.0070 - val_mse: 2.0070\n",
      "Epoch 91/100\n",
      "1262/1262 [==============================] - 110s 87ms/step - loss: 1.7603 - mse: 1.7603 - val_loss: 2.0044 - val_mse: 2.0044\n",
      "Epoch 92/100\n",
      "1262/1262 [==============================] - 109s 87ms/step - loss: 1.7467 - mse: 1.7467 - val_loss: 1.9703 - val_mse: 1.9703\n",
      "Epoch 93/100\n",
      "1262/1262 [==============================] - 111s 88ms/step - loss: 1.7402 - mse: 1.7402 - val_loss: 1.9706 - val_mse: 1.9706\n",
      "Epoch 94/100\n",
      "1262/1262 [==============================] - 112s 88ms/step - loss: 1.7249 - mse: 1.7249 - val_loss: 1.9536 - val_mse: 1.9536\n",
      "Epoch 95/100\n",
      "1262/1262 [==============================] - 109s 87ms/step - loss: 1.7367 - mse: 1.7367 - val_loss: 2.1920 - val_mse: 2.1920\n",
      "Epoch 96/100\n",
      "1262/1262 [==============================] - 112s 89ms/step - loss: 1.7419 - mse: 1.7419 - val_loss: 1.9695 - val_mse: 1.9695\n",
      "Epoch 97/100\n",
      "1262/1262 [==============================] - 111s 88ms/step - loss: 1.7200 - mse: 1.7200 - val_loss: 1.9367 - val_mse: 1.9367\n",
      "Epoch 98/100\n",
      "1262/1262 [==============================] - 119s 95ms/step - loss: 1.7305 - mse: 1.7305 - val_loss: 1.9648 - val_mse: 1.9648\n",
      "Epoch 99/100\n",
      "1262/1262 [==============================] - 108s 86ms/step - loss: 1.7410 - mse: 1.7410 - val_loss: 1.9663 - val_mse: 1.9663\n",
      "Epoch 100/100\n",
      "1262/1262 [==============================] - 108s 85ms/step - loss: 1.7267 - mse: 1.7267 - val_loss: 1.9818 - val_mse: 1.9818\n",
      "Test MSE after pruning: 1.7959885597229004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "2024-02-15 02:44:00.382534: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
       "2024-02-15 02:44:00.388995: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
       "2024-02-15 02:44:00.461562: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
       "2024-02-15 02:44:00.461620: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
       "2024-02-15 02:44:00.461945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
       "2024-02-15 02:44:00.490689: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
       "2024-02-15 02:44:00.491162: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
       "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
       "2024-02-15 02:44:01.119896: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
       "\n",
       "NOTE: Using experimental fast data loading logic. To disable, pass\n",
       "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
       "    https://github.com/tensorflow/tensorboard/issues/4784\n",
       "\n",
       "Address already in use\n",
       "Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmengel/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned model to: /tmp/tmpn7qp4xai.h5\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp0mmr2lme/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0mmr2lme/assets\n",
      "2024-02-15 02:44:06.505315: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-02-15 02:44:06.505385: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-02-15 02:44:06.506434: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp0mmr2lme\n",
      "2024-02-15 02:44:06.511199: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-02-15 02:44:06.511218: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp0mmr2lme\n",
      "2024-02-15 02:44:06.521314: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
      "2024-02-15 02:44:06.524955: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-02-15 02:44:06.613194: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp0mmr2lme\n",
      "2024-02-15 02:44:06.645386: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 138899 microseconds.\n",
      "2024-02-15 02:44:06.718228: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: /tmp/tmp0ah2f0gd.tflite\n",
      "Size of gzipped baseline Keras model: 6482852.00 bytes\n",
      "Size of gzipped pruned Keras model: 2372228.00 bytes\n",
      "Size of gzipped pruned TFlite model: 2370219.00 bytes\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpx8wl_6ag/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpx8wl_6ag/assets\n",
      "2024-02-15 02:44:09.096390: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-02-15 02:44:09.096441: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-02-15 02:44:09.096601: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpx8wl_6ag\n",
      "2024-02-15 02:44:09.098038: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-02-15 02:44:09.098056: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpx8wl_6ag\n",
      "2024-02-15 02:44:09.101752: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-02-15 02:44:09.152835: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpx8wl_6ag\n",
      "2024-02-15 02:44:09.168154: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 71552 microseconds.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quantized and pruned TFLite model to: /tmp/tmpnw8qslgq.tflite\n",
      "Size of gzipped quantized and pruned TFlite model: 339858.00 bytes\n",
      "Evaluated on 0 results so far.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Dimension mismatch. Got 2 but expected 3 for input 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 117\u001b[0m\n\u001b[1;32m    114\u001b[0m interpreter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mInterpreter(model_content\u001b[38;5;241m=\u001b[39mtflite_quant_model)\n\u001b[1;32m    115\u001b[0m interpreter\u001b[38;5;241m.\u001b[39mallocate_tensors()\n\u001b[0;32m--> 117\u001b[0m test_mse \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterpreter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaseline test MSE:\u001b[39m\u001b[38;5;124m'\u001b[39m, mse_baseline[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPruned and quantized TFLite test MSE:\u001b[39m\u001b[38;5;124m'\u001b[39m, test_mse)\n",
      "Cell \u001b[0;32mIn[4], line 26\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(interpreter, x_test, y_test)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Pre-processing: add batch dimension and convert to float32 to match with\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# the model's input data format.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m test_trace \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(test_trace, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 26\u001b[0m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Run inference.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m interpreter\u001b[38;5;241m.\u001b[39minvoke()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:720\u001b[0m, in \u001b[0;36mInterpreter.set_tensor\u001b[0;34m(self, tensor_index, value)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index, value):\n\u001b[1;32m    705\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Sets the value of the input tensor.\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \n\u001b[1;32m    707\u001b[0m \u001b[38;5;124;03m  Note this copies data in `value`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    ValueError: If the interpreter could not set the tensor.\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSetTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set tensor: Dimension mismatch. Got 2 but expected 3 for input 0."
     ]
    }
   ],
   "source": [
    "# get baseline model\n",
    "model = mm.PhaseNet(INPUTSIZE)\n",
    "model.summary()\n",
    "\n",
    "# early stopping callback based on validation loss\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[keras.metrics.MeanSquaredError()],\n",
    ")\n",
    "\n",
    "# train the model\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=BATCHSIZE,\n",
    "    epochs=NUMEPOCHS,\n",
    "    validation_split=VALIDATIONSPLIT,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "# evaluate the model\n",
    "mse_baseline = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test Mean Squared Error: {mse_baseline[0]}\")\n",
    "\n",
    "# Save the model\n",
    "_ , keras_file = tempfile.mkstemp('.h5')\n",
    "model.save(keras_file, include_optimizer=False)\n",
    "print(f\"Saved model to: {keras_file}\")\n",
    "\n",
    "#pruning\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "num_samples = x_train.shape[0] * (1-VALIDATIONSPLIT)\n",
    "end_step = np.ceil(num_samples / BATCHSIZE).astype(np.int32) * NUMEPOCHS\n",
    "\n",
    "pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                                 final_sparsity=0.80,\n",
    "                                                                 begin_step=0,\n",
    "                                                                 end_step=end_step)\n",
    "    }\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "\n",
    "model_for_pruning.summary()\n",
    "\n",
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [ tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "                tfmot.sparsity.keras.PruningSummaries(log_dir=logdir)]\n",
    "\n",
    "pruned_history = model_for_pruning.fit(x_train, y_train, \n",
    "          epochs=NUMEPOCHS, \n",
    "          batch_size=BATCHSIZE,\n",
    "          validation_split=VALIDATIONSPLIT,\n",
    "            callbacks=callbacks)\n",
    "\n",
    "pruned_mse, _ = model_for_pruning.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Test MSE after pruning: {pruned_mse}\")\n",
    "\n",
    "%tensorboard --logdir={logdir}\n",
    "\n",
    "_, keras_pruned_file = tempfile.mkstemp('.h5')\n",
    "# tf.keras.models.save_model(model_for_pruning, keras_pruned_file, include_optimizer=False)\n",
    "model_for_pruning.save(keras_pruned_file, include_optimizer=False)\n",
    "print(f\"Saved pruned model to: {keras_pruned_file}\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_pruning)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "    f.write(pruned_tflite_model)\n",
    "\n",
    "print(f\"Saved pruned TFLite model to: {pruned_tflite_file}\")\n",
    "\n",
    "    \n",
    "# size of the models\n",
    "\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_pruned_file)))\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "    f.write(tflite_quant_model)\n",
    "\n",
    "print(f\"Saved quantized and pruned TFLite model to: {quantized_and_pruned_tflite_file}\")\n",
    "print(\"Size of gzipped quantized and pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))\n",
    "\n",
    "# compare the models\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_mse = evaluate_model(interpreter, x_test, y_test)\n",
    "\n",
    "print('Baseline test MSE:', mse_baseline[0])\n",
    "print('Pruned and quantized TFLite test MSE:', test_mse)\n",
    "print('Pruned and quantized TFLite test MSE:', pruned_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "pruning_params_2_by_4 = {\n",
    "    'sparsity_m_by_n': (2, 4),\n",
    "}\n",
    "\n",
    "pruning_params_sparsity_0_5 = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=0.5,\n",
    "                                                              begin_step=0,\n",
    "                                                              frequency=100)\n",
    "}\n",
    "\n",
    "\n",
    "model = mm.PhaseNetPrunable(INPUTSIZE, pruning_params_2_by_4, pruning_params_sparsity_0_5)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss='mse',\n",
    "                metrics=['mse'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = du.GetDataSet(type=\"phase\",\n",
    "                                                 fname=\"DataSmallFloat.root\",\n",
    "                                                 tname=\"OutputTree\")\n",
    "\n",
    "callbaks = [tfmot.sparsity.keras.UpdatePruningStep()]\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=NUMEPOCHS,\n",
    "                    batch_size=BATCHSIZE,\n",
    "                    validation_split=VALIDATIONSPLIT,\n",
    "                    callbacks=callbaks)\n",
    "\n",
    "pruned_mse, _ = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test MSE after pruning: {pruned_mse}\")\n",
    "\n",
    "model = tfmot.sparsity.keras.strip_pruning(model)\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "_, tflite_file = tempfile.mkstemp('.tflite')\n",
    "print('Saved converted pruned model to:', tflite_file)\n",
    "with open(tflite_file, 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "  # Load tflite file with the created pruned model\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_file, experimental_preserve_all_tensors=True)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "details = interpreter.get_tensor_details()\n",
    "\n",
    "# Weights of the dense layer that has been pruned.\n",
    "tensor_name = 'structural_pruning_dense/MatMul'\n",
    "detail = [x for x in details if tensor_name in x[\"name\"]]\n",
    "\n",
    "# We need the first layer.\n",
    "tensor_data = interpreter.tensor(detail[0][\"index\"])()\n",
    "\n",
    "print(f\"Shape of Dense layer is {tensor_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# The value 24 is chosen for convenience.\n",
    "width = height = 24\n",
    "subset_values_to_display = tensor_data[0:height, 0:width]\n",
    "\n",
    "val_ones = np.ones([height, width])\n",
    "val_zeros = np.zeros([height, width])\n",
    "subset_values_to_display = np.where(abs(subset_values_to_display) > 0, val_ones, val_zeros)\n",
    "\n",
    "\n",
    "plot_separation_lines(height, width)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(subset_values_to_display)\n",
    "plt.colorbar()\n",
    "plt.title(\"Structural pruning for Dense layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights of the convolutional layer that has been pruned with 2 by 4 sparsity.\n",
    "op_details = interpreter._get_ops_details()\n",
    "op_name = 'CONV_2D'\n",
    "op_detail = [x for x in op_details if op_name in x[\"op_name\"]]\n",
    "tensor_data = interpreter.tensor(op_detail[1][\"inputs\"][1])()\n",
    "print(f\"Shape of the weight tensor is {tensor_data.shape}\")\n",
    "\n",
    "\n",
    "weights_to_display = tf.reshape(tensor_data, [tf.reduce_prod(tensor_data.shape[:-1]), -1])\n",
    "weights_to_display = weights_to_display[0:width, 0:height]\n",
    "\n",
    "val_ones = np.ones([height, width])\n",
    "val_zeros = np.zeros([height, width])\n",
    "subset_values_to_display = np.where(abs(weights_to_display) > 1e-9, val_ones, val_zeros)\n",
    "\n",
    "plot_separation_lines(height, width)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(subset_values_to_display)\n",
    "plt.colorbar()\n",
    "plt.title(\"Structurally pruned weights for Conv2D layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
